Step 1:
	Prepare data for tokens embedding of edit scripts.
	Input data: parsed results of patches with GumTree.
	Select token vectors of edit scripts by the value of upper whisker.

Step 2:
	Embed tokens of all selected edit scripts.
	
Step 3:
	Prepare data for features learning of selected edit scripts.
	Vectorize edit scripts with embedded tokens of edit scripts.
	
Step 4:
	Learn features of all selected edit scripts with CNN algorithm.
	Input data: vectorized edit scripts.

Step 5:
	Prepare data for clustering of edit scripts.
	Input data: learned features of edit scripts by CNN.
	
Step 6:
	Clustering of edit scripts with extracted features of edit scripts.
	
Step 7:
	Analyze cluster results to obtain common fix patterns.
	
Step 8:
	Prepare testing data for evaluation.
 	Parse java projects to get the token vectors of all statements.
 
Step 9:
	Prepare data for evaluation.
	Merge token vectors of source code of training data and testing data.
	
Step 10:
	Prepare data for evaluation.
	Embed tokens of source code vectors of training data and testing data.

Step 11:
	Prepare data for evaluation.
	Vectorize data (token vectors of source code) for deep learning.

Step 12:
	Evaluation: extract features of testing data and predict their labels.

Step 13:
	